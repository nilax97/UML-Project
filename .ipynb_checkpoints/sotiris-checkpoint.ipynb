{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4d531a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import numpy as np\n",
    "from rouge_score import rouge_scorer\n",
    "from sklearn.cluster import KMeans\n",
    "import nltk\n",
    "from nltk.stem.snowball import EnglishStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from tqdm.notebook import tqdm\n",
    "from sknetwork.ranking import PageRank\n",
    "from tqdm.notebook import tqdm\n",
    "from itertools import combinations\n",
    "from multiprocess import Pool\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "558d5177-bfcb-4ff9-8da0-32c28f93e930",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_tokenizer(text):\n",
    "    return word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73975b7f-488b-4468-bde7-ab3aa1828559",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sent_list(sents,stem=None):\n",
    "    stemmer = EnglishStemmer()\n",
    "    ans = []\n",
    "    for sent in sents:\n",
    "        words = word_tokenize(sent)\n",
    "        word_stem = [stemmer.stem(w) for w in words]\n",
    "        ans.append(\" \".join(word_stem))\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2141e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_to_string(x):\n",
    "    return x.numpy().decode('UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4f30cfe4-dd97-4ff2-9843-5cb9982c1947",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_similarity_matrix_tr(sents):\n",
    "    n = len(sents)\n",
    "    M = np.zeros([n,n])\n",
    "    \n",
    "    A = {i: set(sent.split()) for i,sent in enumerate(sents)}\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i,n):\n",
    "            if (len(sents[i]) != 1) and (len(sents[j]) != 1) :\n",
    "                m = len(A[i].intersection(A[j])) / (np.log(len(sents[i])+ np.log(len(sents[j]))))\n",
    "                \n",
    "                M[i,j] = M[j,i] = m\n",
    "    return M\n",
    "\n",
    "def create_similarity_matrix_ps(sents,lambda_1=0.7,lambda_2=0.3):\n",
    "    n = len(sents)\n",
    "    M = np.zeros([n,n])\n",
    "    \n",
    "    A = {i: set(sent.split()) for i,sent in enumerate(sents)}\n",
    "        \n",
    "    for i in range(n):\n",
    "        for j in range(i,n):\n",
    "            \n",
    "            if (len(sents[i]) != 1) and (len(sents[j]) != 1) :\n",
    "                m = len(A[i].intersection(A[j])) / (np.log(len(sents[i])+ np.log(len(sents[j]))))\n",
    "                if i == j:\n",
    "                    continue\n",
    "                \n",
    "                M[i,j] = lambda_2 * m\n",
    "                M[j,i] = lambda_1 * m\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3822d6aa-69d4-48da-9c20-70018f477292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set cnn-daily mail/arxiv/pubmed\n",
    "def lead(text,k):\n",
    "    return \" \".join([text[i] for i in range(k)])\n",
    "\n",
    "def text_rank(text,k):\n",
    "    sents = get_sent_list(text,stem='EnglishStemmer')\n",
    "    M = create_similarity_matrix_tr(sents)\n",
    "    pr = PageRank()\n",
    "    scores = pr.fit_transform(M)\n",
    "    ind = np.argpartition(scores, -k)[-k:]\n",
    "    return \" \".join([text[i] for i in ind])\n",
    "\n",
    "def pacsum(text,k):\n",
    "    sents = get_sent_list(text,stem='EnglishStemmer')\n",
    "    M = create_similarity_matrix_ps(sents)\n",
    "    pr = PageRank()\n",
    "    scores = pr.fit_transform(M)\n",
    "    ind = np.argpartition(scores, -k)[-k:]\n",
    "    return \" \".join([text[i] for i in ind])\n",
    "\n",
    "def _oracle_helper(inp):\n",
    "    text,summ_sent = inp\n",
    "    result = []\n",
    "    for i in range(len(text)):\n",
    "        scores = scorer.score(summ_sent,text[i])\n",
    "        \n",
    "    return \n",
    "\n",
    "def oracle(text,summary):\n",
    "    best_combo = []  \n",
    "    s = set()\n",
    "    \n",
    "    for sum_sent in summary:\n",
    "        \n",
    "        best_score = 0\n",
    "        best_idx = 0\n",
    "        \n",
    "        for i in range(len(text)):\n",
    "            if text[i] not in s:\n",
    "                scores = scorer.score(sum_sent,text[i])\n",
    "                if scores[\"rouge1\"].fmeasure > best_score:\n",
    "                    best_score = scores[\"rouge1\"].fmeasure \n",
    "                    best_idx = i\n",
    "        s.add(text[i])\n",
    "        best_combo.append(best_idx)\n",
    "          \n",
    "    return \" \".join([text[i] for i in best_combo])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b415b8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uml_summary(inp):\n",
    "    kind,algo,x = inp\n",
    "    if kind == \"cnn_dailymail\":\n",
    "        key1 = 'article'\n",
    "        key2 = 'highlights'\n",
    "    elif kind == \"scientific_papers/arxiv\" or kind == \"scientific_papers/pubmed\":\n",
    "        key1 = 'article'\n",
    "        key2 = 'abstract'\n",
    "        \n",
    "    text = tensor_to_string(x[key1])\n",
    "    summary = tensor_to_string(x[key2])\n",
    "    \n",
    "    summ_sents = sent_tokenize(summary)\n",
    "    sents = sent_tokenize(text)\n",
    "    \n",
    "    if len(summ_sents) <= len(sents):\n",
    "        k = len(summ_sents)\n",
    "        \n",
    "        if algo == 'lead':\n",
    "            gen_sum = lead(sents,3 if len(sents) >= 3 else len(sents))\n",
    "        elif algo == 'pacsum':\n",
    "            gen_sum = pacsum(sents,k)\n",
    "        elif algo == 'textrank':\n",
    "            gen_sum = text_rank(sents,k)\n",
    "        else:\n",
    "            gen_sum = oracle(sents,summ_sents)\n",
    "        scores = scorer.score(summary,gen_sum)\n",
    "        return scores[\"rouge1\"].fmeasure, scores[\"rouge2\"].fmeasure, scores[\"rougeL\"].fmeasure\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5740baad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algo: lead\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1193463bc994efba050c32b827db7dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11490 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: cnn_dailymail\n",
      "Rouge 1 :  40.06\n",
      "Rouge 2 :  17.48\n",
      "Rouge L :  25.02\n",
      "___\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5be13cf864c49c9baf47cce1936d626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6440 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: scientific_papers/arxiv\n",
      "Rouge 1 :  27.41\n",
      "Rouge 2 :  6.54\n",
      "Rouge L :  15.99\n",
      "___\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d538584641f4e539d6722d2778c2c0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6658 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: scientific_papers/pubmed\n",
      "Rouge 1 :  27.86\n",
      "Rouge 2 :  9.12\n",
      "Rouge L :  17.14\n",
      "___\n",
      "Algo: textrank\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8c9533321ff4986a37269fb7f959ba7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11490 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: cnn_dailymail\n",
      "Rouge 1 :  30.03\n",
      "Rouge 2 :  10.66\n",
      "Rouge L :  17.81\n",
      "___\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20fdd46dce94423aa70f6cb3f875ecef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6440 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: scientific_papers/arxiv\n",
      "Rouge 1 :  34.14\n",
      "Rouge 2 :  10.13\n",
      "Rouge L :  17.04\n",
      "___\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b70403286f904d0f912becd282b2c75f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6658 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: scientific_papers/pubmed\n",
      "Rouge 1 :  38.61\n",
      "Rouge 2 :  14.21\n",
      "Rouge L :  19.37\n",
      "___\n",
      "Algo: pacsum\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "794837a4dba842619f92627f5dd6d54a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11490 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: cnn_dailymail\n",
      "Rouge 1 :  36.66\n",
      "Rouge 2 :  15.89\n",
      "Rouge L :  21.86\n",
      "___\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ddff8355ab24f39b9412e03524c5937",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6440 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: scientific_papers/arxiv\n",
      "Rouge 1 :  39.44\n",
      "Rouge 2 :  12.26\n",
      "Rouge L :  19.22\n",
      "___\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57e9b4a5ac1d4d1d8027c46118f70f23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6658 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: scientific_papers/pubmed\n",
      "Rouge 1 :  41.0\n",
      "Rouge 2 :  15.61\n",
      "Rouge L :  19.98\n",
      "___\n",
      "Algo: oracle\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7e87e43e30a4d378b30987e059483e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11490 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: cnn_dailymail\n",
      "Rouge 1 :  52.37\n",
      "Rouge 2 :  29.21\n",
      "Rouge L :  42.28\n",
      "___\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b284795d9aab4265b29df70ac1fee306",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6440 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: scientific_papers/arxiv\n",
      "Rouge 1 :  58.19\n",
      "Rouge 2 :  28.01\n",
      "Rouge L :  39.38\n",
      "___\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c92000e8bafd4bce89510e69e70aec68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6658 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: scientific_papers/pubmed\n",
      "Rouge 1 :  59.13\n",
      "Rouge 2 :  31.72\n",
      "Rouge L :  41.75\n",
      "___\n"
     ]
    }
   ],
   "source": [
    "datasets = [\"cnn_dailymail\",\"scientific_papers/arxiv\",\"scientific_papers/pubmed\"]\n",
    "# datasets = [\"scientific_papers/arxiv\",\"scientific_papers/pubmed\"]\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2','rougeL'], use_stemmer=True)\n",
    "algos = ['lead','textrank','pacsum','oracle']\n",
    "# algos = ['pacsum']\n",
    "for algo in algos:\n",
    "    print('Algo:',algo)\n",
    "    for ds in datasets:\n",
    "        train, val, test = tfds.load(name=ds, \n",
    "                          split=[\"train\", \"validation\", \"test\"], \n",
    "                          data_dir=\"/mnt/disks/disk-1/data\")\n",
    "\n",
    "        dataset = list(test)\n",
    "        args = zip([ds] * len(dataset),[algo] * len(dataset),dataset)\n",
    "\n",
    "        with Pool(11) as pool:\n",
    "              r = list(tqdm(pool.imap(uml_summary,args), total=len(dataset)))\n",
    "\n",
    "        r = [a for a in r if a]\n",
    "        r1, r2, rl = list(zip(*r))\n",
    "\n",
    "        print('Dataset:',ds)\n",
    "        print(\"Rouge 1 : \",np.round(np.mean(np.asarray(r1))*100,2))\n",
    "        print(\"Rouge 2 : \",np.round(np.mean(np.asarray(r2))*100,2))\n",
    "        print(\"Rouge L : \",np.round(np.mean(np.asarray(rl))*100,2))\n",
    "        print(\"___\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc364836-36d7-4082-ac8d-58223845e37d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854949a0-33c6-4a10-ae0a-1da68deaa1f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
